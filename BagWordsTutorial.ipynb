{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twenty_train.data.shape (11314,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
    "print \"twenty_train.data.shape\", np.array(twenty_train.data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer\n",
    "which is important aspect for our learnvocabulary --> bag-of-words method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts.shape (11314, 130107)\n",
      "X_train_counts   (0, 56979)\t1\n",
      "  (0, 43959)\t1\n",
      "  (0, 58175)\t2\n",
      "  (0, 32863)\t3\n",
      "  (0, 50527)\t2\n",
      "  (0, 111322)\t1\n",
      "  (0, 99721)\t1\n",
      "  (0, 43969)\t5\n",
      "  (0, 32576)\t1\n",
      "  (0, 79569)\t1\n",
      "  (0, 64186)\t2\n",
      "  (0, 29573)\t1\n",
      "  (0, 26656)\t1\n",
      "  (0, 7367)\t1\n",
      "  (0, 54006)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 118983)\t1\n",
      "  (0, 89362)\t1\n",
      "  (0, 37413)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 3411)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 57980)\t1\n",
      "  :\t:\n",
      "  (11313, 39169)\t1\n",
      "  (11313, 26430)\t3\n",
      "  (11313, 42714)\t1\n",
      "  (11313, 125095)\t1\n",
      "  (11313, 25581)\t3\n",
      "  (11313, 5417)\t1\n",
      "  (11313, 62477)\t1\n",
      "  (11313, 71813)\t1\n",
      "  (11313, 50654)\t1\n",
      "  (11313, 20003)\t1\n",
      "  (11313, 67867)\t1\n",
      "  (11313, 118927)\t1\n",
      "  (11313, 40477)\t1\n",
      "  (11313, 100058)\t1\n",
      "  (11313, 50958)\t1\n",
      "  (11313, 92999)\t1\n",
      "  (11313, 25578)\t1\n",
      "  (11313, 81822)\t1\n",
      "  (11313, 26411)\t3\n",
      "  (11313, 119489)\t1\n",
      "  (11313, 78724)\t2\n",
      "  (11313, 74730)\t4\n",
      "  (11313, 105878)\t1\n",
      "  (11313, 53400)\t1\n",
      "  (11313, 34780)\t3\n",
      "27366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print \"X_train_counts.shape\", X_train_counts.shape\n",
    "print \"X_train_counts\", X_train_counts\n",
    "print count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed counted-vectors into TfidfTransformer\n",
    "* So we will know "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tf.shape (11314, 130107)\n",
      "  (0, 56979)\t0.065795169496\n",
      "  (0, 43959)\t0.065795169496\n",
      "  (0, 58175)\t0.131590338992\n",
      "  (0, 32863)\t0.197385508488\n",
      "  (0, 50527)\t0.131590338992\n",
      "  (0, 111322)\t0.065795169496\n",
      "  (0, 99721)\t0.065795169496\n",
      "  (0, 43969)\t0.32897584748\n",
      "  (0, 32576)\t0.065795169496\n",
      "  (0, 79569)\t0.065795169496\n",
      "  (0, 64186)\t0.131590338992\n",
      "  (0, 29573)\t0.065795169496\n",
      "  (0, 26656)\t0.065795169496\n",
      "  (0, 7367)\t0.065795169496\n",
      "  (0, 54006)\t0.065795169496\n",
      "  (0, 90379)\t0.065795169496\n",
      "  (0, 118983)\t0.065795169496\n",
      "  (0, 89362)\t0.065795169496\n",
      "  (0, 37413)\t0.065795169496\n",
      "  (0, 76032)\t0.065795169496\n",
      "  (0, 3411)\t0.065795169496\n",
      "  (0, 87620)\t0.065795169496\n",
      "  (0, 95162)\t0.065795169496\n",
      "  (0, 64095)\t0.065795169496\n",
      "  (0, 57980)\t0.065795169496\n",
      "  :\t:\n",
      "  (0, 115475)\t0.131590338992\n",
      "  (0, 75004)\t0.065795169496\n",
      "  (0, 30044)\t0.263180677984\n",
      "  (0, 115701)\t0.065795169496\n",
      "  (0, 66608)\t0.131590338992\n",
      "  (0, 52907)\t0.065795169496\n",
      "  (0, 32976)\t0.065795169496\n",
      "  (0, 103024)\t0.065795169496\n",
      "  (0, 30142)\t0.065795169496\n",
      "  (0, 1131)\t0.065795169496\n",
      "  (0, 124061)\t0.131590338992\n",
      "  (0, 34842)\t0.065795169496\n",
      "  (0, 1142)\t0.065795169496\n",
      "  (0, 123575)\t0.131590338992\n",
      "  (0, 73201)\t0.065795169496\n",
      "  (0, 68766)\t0.131590338992\n",
      "  (0, 68532)\t0.131590338992\n",
      "  (0, 50111)\t0.065795169496\n",
      "  (0, 54359)\t0.065795169496\n",
      "  (0, 75053)\t0.065795169496\n",
      "  (0, 51777)\t0.065795169496\n",
      "  (0, 106984)\t0.065795169496\n",
      "  (0, 116575)\t0.065795169496\n",
      "  (0, 110697)\t0.065795169496\n",
      "  (0, 114579)\t0.065795169496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "print \"X_train_tf.shape\", X_train_tf.shape\n",
    "print X_train_tf[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf.shape (11314, 130107)\n",
      "clf MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "X_new_counts   (0, 59626)\t1\n",
      "  (0, 68532)\t1\n",
      "  (0, 76876)\t1\n",
      "  (1, 54467)\t1\n",
      "  (1, 59961)\t1\n",
      "  (1, 68532)\t1\n",
      "  (1, 89860)\t1\n",
      "  (1, 90045)\t1\n",
      "  (1, 114455)\t1\n",
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print \"X_train_tfidf.shape\", X_train_tfidf.shape\n",
    "\n",
    "#Training a classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "print \"clf\", clf\n",
    "\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "print \"X_new_counts\", X_new_counts\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "  print '%r => %s' % (doc, twenty_train.target_names[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes 0.77389803505\n",
      "SVM 0.823818374934\n"
     ]
    }
   ],
   "source": [
    "#Building a pipeline\n",
    "#vectorizer => transformer => classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()) ])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print \"naive bayes\", np.mean(predicted == twenty_test.target)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print \"SVM\", np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
